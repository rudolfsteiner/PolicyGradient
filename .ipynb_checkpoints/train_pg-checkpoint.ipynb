{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import logz\n",
    "import scipy.signal\n",
    "import os\n",
    "import time\n",
    "import inspect\n",
    "from multiprocessing import Process\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#============================================================================================#\n",
    "# Utilities\n",
    "#============================================================================================#\n",
    "\n",
    "def build_mlp(\n",
    "        input_placeholder, \n",
    "        output_size,\n",
    "        scope, \n",
    "        n_layers=2, \n",
    "        size=64, \n",
    "        activation=tf.tanh,\n",
    "        output_activation=None\n",
    "        ):\n",
    "    #========================================================================================#\n",
    "    #                           ----------SECTION 3----------\n",
    "    # Network building\n",
    "    #\n",
    "    # Your code should make a feedforward neural network (also called a multilayer perceptron)\n",
    "    # with 'n_layers' hidden layers of size 'size' units. \n",
    "    # \n",
    "    # The output layer should have size 'output_size' and activation 'output_activation'.\n",
    "    #\n",
    "    # Hint: use tf.layers.dense\n",
    "    #========================================================================================#\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        # YOUR_CODE_HERE\n",
    "        input_layers = input_placeholder\n",
    "        for i in range(n_layers):\n",
    "            input_layers = tf.layers.dense(inputs = input_layers, \n",
    "                                           units = size, \n",
    "                                           activation = activation, \n",
    "                                           name = scope + str(i+1) + \"_layer\")\n",
    "            \n",
    "        output_layer = tf.layers.dense(inputs = input_layers, \n",
    "                                 units = output_size, \n",
    "                                 activation = output_activation, \n",
    "                                 name = scope + \"output_layer\")\n",
    "        \n",
    "        return output_layer\n",
    "\n",
    "def pathlength(path):\n",
    "    return len(path[\"reward\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#============================================================================================#\n",
    "# Policy Gradient\n",
    "#============================================================================================#\n",
    "\n",
    "def train_PG(exp_name='',\n",
    "             env_name='CartPole-v0',\n",
    "             n_iter=100, \n",
    "             gamma=1.0, \n",
    "             min_timesteps_per_batch=1000, \n",
    "             max_path_length=None,\n",
    "             learning_rate=5e-3, \n",
    "             reward_to_go=True, \n",
    "             animate=True, \n",
    "             logdir=None, \n",
    "             normalize_advantages=True,\n",
    "             nn_baseline=False, \n",
    "             seed=0,\n",
    "             # network arguments\n",
    "             n_layers=1,\n",
    "             size=32\n",
    "             ):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Configure output directory for logging\n",
    "    logz.configure_output_dir(logdir)\n",
    "\n",
    "    # Log experimental parameters\n",
    "    args = inspect.getargspec(train_PG)[0]\n",
    "    locals_ = locals()\n",
    "    params = {k: locals_[k] if k in locals_ else None for k in args}\n",
    "    logz.save_params(params)\n",
    "\n",
    "    # Set random seeds\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Make the gym environment\n",
    "    env = gym.make(env_name)\n",
    "    \n",
    "    # Is this env continuous, or discrete?\n",
    "    discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "\n",
    "    # Maximum length for episodes\n",
    "    max_path_length = max_path_length or env.spec.max_episode_steps\n",
    "    \n",
    "    loss_before = 1000\n",
    "\n",
    "    #========================================================================================#\n",
    "    # Notes on notation:\n",
    "    # \n",
    "    # Symbolic variables have the prefix sy_, to distinguish them from the numerical values\n",
    "    # that are computed later in the function\n",
    "    # \n",
    "    # Prefixes and suffixes:\n",
    "    # ob - observation \n",
    "    # ac - action\n",
    "    # _no - this tensor should have shape (batch size /n/, observation dim)\n",
    "    # _na - this tensor should have shape (batch size /n/, action dim)\n",
    "    # _n  - this tensor should have shape (batch size /n/)\n",
    "    # \n",
    "    # Note: batch size /n/ is defined at runtime, and until then, the shape for that axis\n",
    "    # is None\n",
    "    #========================================================================================#\n",
    "\n",
    "    # Observation and action sizes\n",
    "    ob_dim = env.observation_space.shape[0]\n",
    "    ac_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "\n",
    "    #========================================================================================#\n",
    "    #                           ----------SECTION 4----------\n",
    "    # Placeholders\n",
    "    # \n",
    "    # Need these for batch observations / actions / advantages in policy gradient loss function.\n",
    "    #========================================================================================#\n",
    "\n",
    "    sy_ob_no = tf.placeholder(shape=[None, ob_dim], name=\"ob\", dtype=tf.float32)\n",
    "    if discrete:\n",
    "        sy_ac_na = tf.placeholder(shape=[None], name=\"ac\", dtype=tf.int32) \n",
    "    else:\n",
    "        sy_ac_na = tf.placeholder(shape=[None, ac_dim], name=\"ac\", dtype=tf.float32) \n",
    "\n",
    "    # Define a placeholder for advantages\n",
    "    sy_adv_n = tf.placeholder(shape=[None], name = \"adv\", dtype = tf.float32) #TODO\n",
    "\n",
    "\n",
    "    #========================================================================================#\n",
    "    #                           ----------SECTION 4----------\n",
    "    # Networks\n",
    "    # \n",
    "    # Make symbolic operations for\n",
    "    #   1. Policy network outputs which describe the policy distribution.\n",
    "    #       a. For the discrete case, just logits for each action.\n",
    "    #\n",
    "    #       b. For the continuous case, the mean / log std of a Gaussian distribution over \n",
    "    #          actions.\n",
    "    #\n",
    "    #      Hint: use the 'build_mlp' function you defined in utilities.\n",
    "    #\n",
    "    #      Note: these ops should be functions of the placeholder 'sy_ob_no'\n",
    "    #\n",
    "    #   2. Producing samples stochastically from the policy distribution.\n",
    "    #       a. For the discrete case, an op that takes in logits and produces actions.\n",
    "    #\n",
    "    #          Should have shape [None]\n",
    "    #\n",
    "    #       b. For the continuous case, use the reparameterization trick:\n",
    "    #          The output from a Gaussian distribution with mean 'mu' and std 'sigma' is\n",
    "    #\n",
    "    #               mu + sigma * z,         z ~ N(0, I)\n",
    "    #\n",
    "    #          This reduces the problem to just sampling z. (Hint: use tf.random_normal!)\n",
    "    #\n",
    "    #          Should have shape [None, ac_dim]\n",
    "    #\n",
    "    #      Note: these ops should be functions of the policy network output ops.\n",
    "    #\n",
    "    #   3. Computing the log probability of a set of actions that were actually taken, \n",
    "    #      according to the policy.\n",
    "    #\n",
    "    #      Note: these ops should be functions of the placeholder 'sy_ac_na', and the \n",
    "    #      policy network output ops.\n",
    "    #   \n",
    "    #========================================================================================#\n",
    "\n",
    "    if discrete:\n",
    "        # YOUR_CODE_HERE\n",
    "        sy_logits_na = build_mlp(sy_ob_no, ac_dim, 'discrete_mlp', n_layers, size) #TODO\n",
    "        sy_sampled_ac = tf.reshape(tf.multinomial(sy_logits_na, 1), [-1]) #TODO # Hint: Use the tf.multinomial op\n",
    "        sy_logprob_n = -tf.nn.sparse_softmax_cross_entropy_with_logits(labels=sy_ac_na, logits=sy_logits_na) #TODO\n",
    "\n",
    "    else:\n",
    "        # YOUR_CODE_HERE\n",
    "        sy_mean = build_mlp(sy_ob_no, ac_dim, \"continuous_mlp\", n_layers, size) #TODO\n",
    "        sy_logstd = tf.Variable(tf.zeros([1, ac_dim]), name='logstd',\n",
    "                dtype=tf.float32) #TODO # logstd should just be a trainable variable, not a network output.\n",
    "        sy_std = tf.exp(sy_logstd)\n",
    "        sy_sampled_ac = tf.random_normal(shape= tf.shape(sy_mean), mean = sy_mean, stddev = sy_std) #sy_mean + sy_std * tf.random_normal(tf.shape(sy_mean)) #TODO\n",
    "        sy_logprob_n = tf.contrib.distributions.MultivariateNormalDiag(loc=sy_mean, scale_diag=sy_std).log_prob(sy_ac_na) #TODO  # Hint: Use the log probability under a multivariate gaussian. \n",
    "\n",
    "\n",
    "\n",
    "    #========================================================================================#\n",
    "    #                           ----------SECTION 4----------\n",
    "    # Loss Function and Training Operation\n",
    "    #========================================================================================#\n",
    "\n",
    "    loss = - tf.reduce_mean(sy_logprob_n * sy_adv_n) #TODO # Loss function that we'll differentiate to get the policy gradient.\n",
    "    update_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "    #========================================================================================#\n",
    "    #                           ----------SECTION 5----------\n",
    "    # Optional Baseline\n",
    "    #========================================================================================#\n",
    "\n",
    "    if nn_baseline:\n",
    "        baseline_prediction = tf.squeeze(build_mlp(\n",
    "                                sy_ob_no, \n",
    "                                1, \n",
    "                                \"nn_baseline\",\n",
    "                                n_layers=n_layers,\n",
    "                                size=size))\n",
    "        # Define placeholders for targets, a loss function and an update op for fitting a \n",
    "        # neural network baseline. These will be used to fit the neural network baseline. \n",
    "        # YOUR_CODE_HERE\n",
    "        baseline_targets = tf.placeholder(shape = [None,], name = \"baseline_targets\", dtype = tf.float32)\n",
    "        baseline_loss = tf.nn.l2_loss(baseline_prediction - baseline_targets)\n",
    "        baseline_update_op = tf.train.AdamOptimizer(learning_rate).minimize(baseline_loss) #TODO\n",
    "\n",
    "\n",
    "    #========================================================================================#\n",
    "    # Tensorflow Engineering: Config, Session, Variable initialization\n",
    "    #========================================================================================#\n",
    "\n",
    "    tf_config = tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1) \n",
    "\n",
    "    sess = tf.Session(config=tf_config)\n",
    "    sess.__enter__() # equivalent to `with sess:`\n",
    "    tf.global_variables_initializer().run() #pylint: disable=E1101\n",
    "\n",
    "\n",
    "    #print(\"reach Training loop\")\n",
    "    #========================================================================================#\n",
    "    # Training Loop\n",
    "    #========================================================================================#\n",
    "\n",
    "    total_timesteps = 0\n",
    "\n",
    "    for itr in range(n_iter):\n",
    "        print(\"********** Iteration %i ************\"%itr)\n",
    "\n",
    "        # Collect paths until we have enough timesteps\n",
    "        timesteps_this_batch = 0\n",
    "        paths = []\n",
    "        while True:\n",
    "            ob = env.reset()\n",
    "            obs, acs, rewards = [], [], []\n",
    "            animate_this_episode=(len(paths)==0 and (itr % 10 == 0) and animate)\n",
    "            steps = 0\n",
    "            while True:\n",
    "                if animate_this_episode:\n",
    "                    env.render()\n",
    "                    time.sleep(0.05)\n",
    "                obs.append(ob)\n",
    "                ac = sess.run(sy_sampled_ac, feed_dict={sy_ob_no : ob[None]})\n",
    "                ac = ac[0]\n",
    "                acs.append(ac)\n",
    "\n",
    "                #print(\"current ac:\", ac)\n",
    "                #print(\"before ob:\", ob)\n",
    "                ob, rew, done, _ = env.step(ac)\n",
    "                #print(\"After ob:\", ob)\n",
    "                #print(\"rew:\", rew)\n",
    "                #print(\"done:\", done)\n",
    "                rewards.append(rew)\n",
    "                steps += 1\n",
    "                if done or steps > max_path_length:\n",
    "                    break\n",
    "            path = {\"observation\" : np.array(obs), \n",
    "                    \"reward\" : np.array(rewards), \n",
    "                    \"action\" : np.array(acs)}\n",
    "            paths.append(path)\n",
    "            timesteps_this_batch += pathlength(path)\n",
    "            if timesteps_this_batch > min_timesteps_per_batch:\n",
    "                break\n",
    "        total_timesteps += timesteps_this_batch\n",
    "\n",
    "        # Build arrays for observation, action for the policy gradient update by concatenating \n",
    "        # across paths\n",
    "        ob_no = np.concatenate([path[\"observation\"] for path in paths])\n",
    "        ac_na = np.concatenate([path[\"action\"] for path in paths])\n",
    "\n",
    "        #====================================================================================#\n",
    "        #                           ----------SECTION 4----------\n",
    "        # Computing Q-values\n",
    "        #\n",
    "        # Your code should construct numpy arrays for Q-values which will be used to compute\n",
    "        # advantages (which will in turn be fed to the placeholder you defined above). \n",
    "        #\n",
    "        # Recall that the expression for the policy gradient PG is\n",
    "        #\n",
    "        #       PG = E_{tau} [sum_{t=0}^T grad log pi(a_t|s_t) * (Q_t - b_t )]\n",
    "        #\n",
    "        # where \n",
    "        #\n",
    "        #       tau=(s_0, a_0, ...) is a trajectory,\n",
    "        #       Q_t is the Q-value at time t, Q^{pi}(s_t, a_t),\n",
    "        #       and b_t is a baseline which may depend on s_t. \n",
    "        #\n",
    "        # You will write code for two cases, controlled by the flag 'reward_to_go':\n",
    "        #\n",
    "        #   Case 1: trajectory-based PG \n",
    "        #\n",
    "        #       (reward_to_go = False)\n",
    "        #\n",
    "        #       Instead of Q^{pi}(s_t, a_t), we use the total discounted reward summed over \n",
    "        #       entire trajectory (regardless of which time step the Q-value should be for). \n",
    "        #\n",
    "        #       For this case, the policy gradient estimator is\n",
    "        #\n",
    "        #           E_{tau} [sum_{t=0}^T grad log pi(a_t|s_t) * Ret(tau)]\n",
    "        #\n",
    "        #       where\n",
    "        #\n",
    "        #           Ret(tau) = sum_{t'=0}^T gamma^t' r_{t'}.\n",
    "        #\n",
    "        #       Thus, you should compute\n",
    "        #\n",
    "        #           Q_t = Ret(tau)\n",
    "        #\n",
    "        #   Case 2: reward-to-go PG \n",
    "        #\n",
    "        #       (reward_to_go = True)\n",
    "        #\n",
    "        #       Here, you estimate Q^{pi}(s_t, a_t) by the discounted sum of rewards starting\n",
    "        #       from time step t. Thus, you should compute\n",
    "        #\n",
    "        #           Q_t = sum_{t'=t}^T gamma^(t'-t) * r_{t'}\n",
    "        #\n",
    "        #\n",
    "        # Store the Q-values for all timesteps and all trajectories in a variable 'q_n',\n",
    "        # like the 'ob_no' and 'ac_na' above. \n",
    "        #\n",
    "        #====================================================================================#\n",
    "        \n",
    "        # YOUR_CODE_HERE\n",
    "        #q_n = TODO\n",
    "        q_n = []\n",
    "        \n",
    "        for path in paths:\n",
    "            r_nr = path[\"reward\"]\n",
    "            step_n = len(r_nr)\n",
    "            \n",
    "            if reward_to_go:\n",
    "                q = [np.sum(np.power(gamma, np.arange(step_n-t))* r_nr[t:]) for t in range(step_n)]\n",
    "            else:\n",
    "                q = [np.sum(np.power(gamma, np.arange(step_n) * r_nr)) for t in range(step_n)]\n",
    "                \n",
    "            q_n.extend(q)\n",
    "        #if reward_to_go:\n",
    "            \n",
    "\n",
    "        #====================================================================================#\n",
    "        #                           ----------SECTION 5----------\n",
    "        # Computing Baselines\n",
    "        #====================================================================================#\n",
    "\n",
    "        if nn_baseline:\n",
    "            # If nn_baseline is True, use your neural network to predict reward-to-go\n",
    "            # at each timestep for each trajectory, and save the result in a variable 'b_n'\n",
    "            # like 'ob_no', 'ac_na', and 'q_n'.\n",
    "            #\n",
    "            # Hint #bl1: rescale the output from the nn_baseline to match the statistics\n",
    "            # (mean and std) of the current or previous batch of Q-values. (Goes with Hint\n",
    "            # #bl2 below.)\n",
    "\n",
    "            b_n = sess.run(baseline_prediction, feed_dict = {sy_ob_no: ob_no}) #TODO\n",
    "            b_n_norm = (b_n - np.mean(b_n))/ (np.std(b_n,axis = 0) + 1e-7)\n",
    "            b_n = b_n_norm * np.std(q_n, axis = 0) + np.mean(q_n, axis = 0)\n",
    "            adv_n = q_n - b_n\n",
    "        else:\n",
    "            adv_n = q_n.copy()\n",
    "        \n",
    "        #====================================================================================#\n",
    "        #                           ----------SECTION 4----------\n",
    "        # Advantage Normalization\n",
    "        #====================================================================================#\n",
    "\n",
    "        if normalize_advantages:\n",
    "            # On the next line, implement a trick which is known empirically to reduce variance\n",
    "            # in policy gradient methods: normalize adv_n to have mean zero and std=1. \n",
    "            # YOUR_CODE_HERE\n",
    "            #pass\n",
    "            adv_n = (adv_n - np.mean(adv_n, axis = 0)) / (np.std(adv_n, axis = 0) + 1e-7)\n",
    "\n",
    "\n",
    "        #====================================================================================#\n",
    "        #                           ----------SECTION 5----------\n",
    "        # Optimizing Neural Network Baseline\n",
    "        #====================================================================================#\n",
    "        if nn_baseline:\n",
    "            # ----------SECTION 5----------\n",
    "            # If a neural network baseline is used, set up the targets and the inputs for the \n",
    "            # baseline. \n",
    "            # \n",
    "            # Fit it to the current batch in order to use for the next iteration. Use the \n",
    "            # baseline_update_op you defined earlier.\n",
    "            #\n",
    "            # Hint #bl2: Instead of trying to target raw Q-values directly, rescale the \n",
    "            # targets to have mean zero and std=1. (Goes with Hint #bl1 above.)\n",
    "\n",
    "            # YOUR_CODE_HERE\n",
    "            #pass\n",
    "            q_n_norm = (q_n - np.mean(q_n, axis = 0)) / (np.std(q_n, axis = 0) + 1e-7)\n",
    "            sess.run(baseline_update_op, feed_dict = {sy_ob_no: ob_no, baseline_targets: q_n_norm})\n",
    "\n",
    "        #====================================================================================#\n",
    "        #                           ----------SECTION 4----------\n",
    "        # Performing the Policy Update\n",
    "        #====================================================================================#\n",
    "\n",
    "        # Call the update operation necessary to perform the policy gradient update based on \n",
    "        # the current batch of rollouts.\n",
    "        # \n",
    "        # For debug purposes, you may wish to save the value of the loss function before\n",
    "        # and after an update, and then log them below. \n",
    "        \n",
    "        # YOUR_CODE_HERE\n",
    "        feed_dict = {sy_ob_no: ob_no, sy_ac_na: ac_na, sy_adv_n: adv_n}\n",
    "        #loss_before = sess.run(loss, feed_dict = feed_dict)\n",
    "        _, loss_after = sess.run([update_op, loss], feed_dict = feed_dict)\n",
    "\n",
    "        # Log diagnostics\n",
    "        \n",
    "        #print(\"log part is here?\")\n",
    "        returns = [path[\"reward\"].sum() for path in paths]\n",
    "        ep_lengths = [pathlength(path) for path in paths]\n",
    "        logz.log_tabular(\"Time\", time.time() - start)\n",
    "        logz.log_tabular(\"Loss Delta\", loss_before - loss_after)\n",
    "        logz.log_tabular(\"Loss After\", loss_after)\n",
    "        logz.log_tabular(\"Iteration\", itr)\n",
    "        logz.log_tabular(\"AverageReturn\", np.mean(returns))\n",
    "        logz.log_tabular(\"StdReturn\", np.std(returns))\n",
    "        logz.log_tabular(\"MaxReturn\", np.max(returns))\n",
    "        logz.log_tabular(\"MinReturn\", np.min(returns))\n",
    "        logz.log_tabular(\"EpLenMean\", np.mean(ep_lengths))\n",
    "        logz.log_tabular(\"EpLenStd\", np.std(ep_lengths))\n",
    "        logz.log_tabular(\"TimestepsThisBatch\", timesteps_this_batch)\n",
    "        logz.log_tabular(\"TimestepsSoFar\", total_timesteps)\n",
    "        logz.dump_tabular()\n",
    "        logz.pickle_tf_vars()\n",
    "        \n",
    "        loss_before = loss_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runmain(env_name, \n",
    "           exp_name = 'vpg',\n",
    "           render = False,\n",
    "           discount = 1.0, \n",
    "           n_iter = 100, \n",
    "           batch_size = 1000, \n",
    "           ep_len = -1., \n",
    "           learning_rate = 5e-3,\n",
    "           reward_to_go = False,\n",
    "           dont_normalize_advantages = False,\n",
    "           nn_baseline = False,\n",
    "           seed = 1, \n",
    "           n_experiments = 1,\n",
    "           n_layers = 1,\n",
    "           size = 32):\n",
    "    \n",
    "    \"\"\"\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('env_name', type=str)\n",
    "    parser.add_argument('--exp_name', type=str, default='vpg')\n",
    "    parser.add_argument('--render', action='store_true')\n",
    "    parser.add_argument('--discount', type=float, default=1.0)\n",
    "    parser.add_argument('--n_iter', '-n', type=int, default=100)\n",
    "    parser.add_argument('--batch_size', '-b', type=int, default=1000)\n",
    "    parser.add_argument('--ep_len', '-ep', type=float, default=-1.)\n",
    "    parser.add_argument('--learning_rate', '-lr', type=float, default=5e-3)\n",
    "    parser.add_argument('--reward_to_go', '-rtg', action='store_true')\n",
    "    parser.add_argument('--dont_normalize_advantages', '-dna', action='store_true')\n",
    "    parser.add_argument('--nn_baseline', '-bl', action='store_true')\n",
    "    parser.add_argument('--seed', type=int, default=1)\n",
    "    parser.add_argument('--n_experiments', '-e', type=int, default=1)\n",
    "    parser.add_argument('--n_layers', '-l', type=int, default=1)\n",
    "    parser.add_argument('--size', '-s', type=int, default=32)\n",
    "    args = parser.parse_args()\n",
    "    \"\"\"\n",
    "    \n",
    "    if not(os.path.exists('data')):\n",
    "        os.makedirs('data')\n",
    "    logdir = exp_name + '_' + env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "    logdir = os.path.join('data', logdir)\n",
    "    if not(os.path.exists(logdir)):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    max_path_length = ep_len if ep_len > 0 else None\n",
    "\n",
    "    for e in range(n_experiments):\n",
    "        #print('n_experiments:', n_experiments)\n",
    "        seed = seed + 10*e\n",
    "        print('Running experiment with seed %d'%seed)\n",
    "        def train_func():\n",
    "            train_PG(\n",
    "                exp_name=exp_name,\n",
    "                env_name=env_name,\n",
    "                n_iter=n_iter,\n",
    "                gamma=discount,\n",
    "                min_timesteps_per_batch=batch_size,\n",
    "                max_path_length=max_path_length,\n",
    "                learning_rate=learning_rate,\n",
    "                reward_to_go=reward_to_go,\n",
    "                animate=render,\n",
    "                logdir=os.path.join(logdir,'%d'%seed),\n",
    "                normalize_advantages=not(dont_normalize_advantages),\n",
    "                nn_baseline=nn_baseline, \n",
    "                seed=seed,\n",
    "                n_layers=n_layers,\n",
    "                size=size\n",
    "                )\n",
    "        # Awkward hacky process runs, because Tensorflow does not like\n",
    "        # repeatedly calling train_PG in the same thread.\n",
    "        p = Process(target=train_func, args=tuple())\n",
    "        p.start()\n",
    "        p.join()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrunmain('CartPole-v0', \\n        n_iter = 100, \\n        batch_size = 1000 , \\n        n_experiments = 5,  \\n        dont_normalize_advantages = True,\\n        reward_to_go = True,\\n        nn_baseline = True,\\n        exp_name = 'sb_bl_rtg_dna',\\n        n_layers = 2)\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "runmain('CartPole-v0', \n",
    "        n_iter = 100, \n",
    "        batch_size = 1000 , \n",
    "        n_experiments = 5,  \n",
    "        dont_normalize_advantages = True,\n",
    "        reward_to_go = True,\n",
    "        nn_baseline = True,\n",
    "        exp_name = 'sb_bl_rtg_dna')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_experiments: 1\n",
      "Running experiment with seed 1\n",
      "\u001b[32;1mLogging data to data/lb_bl_rtg_dna_HalfCheetah-v1_01-05-2018_15-40-59/1/log.txt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "[2018-05-01 15:40:59,445] Making new env: HalfCheetah-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration 0 ************\n",
      "----------------------------------------\n",
      "|               Time |            8.66 |\n",
      "|         Loss Delta |           1e+03 |\n",
      "|         Loss After |         -0.0849 |\n",
      "|          Iteration |               0 |\n",
      "|      AverageReturn |            -110 |\n",
      "|          StdReturn |            37.7 |\n",
      "|          MaxReturn |           -34.1 |\n",
      "|          MinReturn |            -200 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        5.13e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 1 ************\n",
      "----------------------------------------\n",
      "|               Time |            16.5 |\n",
      "|         Loss Delta |        -0.00433 |\n",
      "|         Loss After |         -0.0806 |\n",
      "|          Iteration |               1 |\n",
      "|      AverageReturn |            -111 |\n",
      "|          StdReturn |            46.4 |\n",
      "|          MaxReturn |             -49 |\n",
      "|          MinReturn |            -258 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.03e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 2 ************\n",
      "----------------------------------------\n",
      "|               Time |              23 |\n",
      "|         Loss Delta |          0.0189 |\n",
      "|         Loss After |         -0.0994 |\n",
      "|          Iteration |               2 |\n",
      "|      AverageReturn |            -109 |\n",
      "|          StdReturn |            38.7 |\n",
      "|          MaxReturn |             -18 |\n",
      "|          MinReturn |            -204 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.54e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 3 ************\n",
      "----------------------------------------\n",
      "|               Time |            29.7 |\n",
      "|         Loss Delta |        -0.00185 |\n",
      "|         Loss After |         -0.0976 |\n",
      "|          Iteration |               3 |\n",
      "|      AverageReturn |            -110 |\n",
      "|          StdReturn |            32.7 |\n",
      "|          MaxReturn |            2.34 |\n",
      "|          MinReturn |            -182 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.05e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 4 ************\n",
      "----------------------------------------\n",
      "|               Time |            36.1 |\n",
      "|         Loss Delta |         -0.0327 |\n",
      "|         Loss After |         -0.0649 |\n",
      "|          Iteration |               4 |\n",
      "|      AverageReturn |            -101 |\n",
      "|          StdReturn |            47.4 |\n",
      "|          MaxReturn |           -25.1 |\n",
      "|          MinReturn |            -247 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.57e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 5 ************\n",
      "----------------------------------------\n",
      "|               Time |            42.7 |\n",
      "|         Loss Delta |         0.00807 |\n",
      "|         Loss After |          -0.073 |\n",
      "|          Iteration |               5 |\n",
      "|      AverageReturn |            -107 |\n",
      "|          StdReturn |            42.9 |\n",
      "|          MaxReturn |           -22.3 |\n",
      "|          MinReturn |            -225 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.08e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 6 ************\n",
      "----------------------------------------\n",
      "|               Time |            48.2 |\n",
      "|         Loss Delta |           0.013 |\n",
      "|         Loss After |          -0.086 |\n",
      "|          Iteration |               6 |\n",
      "|      AverageReturn |           -83.6 |\n",
      "|          StdReturn |            41.9 |\n",
      "|          MaxReturn |           -28.5 |\n",
      "|          MinReturn |            -202 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.59e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 7 ************\n",
      "----------------------------------------\n",
      "|               Time |            55.2 |\n",
      "|         Loss Delta |          0.0247 |\n",
      "|         Loss After |          -0.111 |\n",
      "|          Iteration |               7 |\n",
      "|      AverageReturn |           -82.6 |\n",
      "|          StdReturn |              29 |\n",
      "|          MaxReturn |           -29.2 |\n",
      "|          MinReturn |            -142 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.11e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 8 ************\n",
      "----------------------------------------\n",
      "|               Time |            62.5 |\n",
      "|         Loss Delta |           0.025 |\n",
      "|         Loss After |          -0.136 |\n",
      "|          Iteration |               8 |\n",
      "|      AverageReturn |           -80.3 |\n",
      "|          StdReturn |            30.9 |\n",
      "|          MaxReturn |           -13.8 |\n",
      "|          MinReturn |            -173 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.62e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 9 ************\n",
      "----------------------------------------\n",
      "|               Time |            69.5 |\n",
      "|         Loss Delta |         -0.0312 |\n",
      "|         Loss After |          -0.104 |\n",
      "|          Iteration |               9 |\n",
      "|      AverageReturn |           -98.3 |\n",
      "|          StdReturn |            40.3 |\n",
      "|          MaxReturn |           -13.2 |\n",
      "|          MinReturn |            -246 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        5.13e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 10 ************\n",
      "----------------------------------------\n",
      "|               Time |            76.7 |\n",
      "|         Loss Delta |          0.0137 |\n",
      "|         Loss After |          -0.118 |\n",
      "|          Iteration |              10 |\n",
      "|      AverageReturn |             -80 |\n",
      "|          StdReturn |            30.5 |\n",
      "|          MaxReturn |             -22 |\n",
      "|          MinReturn |            -136 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        5.65e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 11 ************\n",
      "----------------------------------------\n",
      "|               Time |            83.5 |\n",
      "|         Loss Delta |         0.00707 |\n",
      "|         Loss After |          -0.125 |\n",
      "|          Iteration |              11 |\n",
      "|      AverageReturn |           -73.4 |\n",
      "|          StdReturn |            28.9 |\n",
      "|          MaxReturn |           -12.6 |\n",
      "|          MinReturn |            -129 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        6.16e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 12 ************\n",
      "----------------------------------------\n",
      "|               Time |            91.2 |\n",
      "|         Loss Delta |         -0.0293 |\n",
      "|         Loss After |         -0.0959 |\n",
      "|          Iteration |              12 |\n",
      "|      AverageReturn |           -72.3 |\n",
      "|          StdReturn |            29.5 |\n",
      "|          MaxReturn |           -8.41 |\n",
      "|          MinReturn |            -158 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        6.67e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 13 ************\n",
      "----------------------------------------\n",
      "|               Time |            97.4 |\n",
      "|         Loss Delta |        -0.00591 |\n",
      "|         Loss After |           -0.09 |\n",
      "|          Iteration |              13 |\n",
      "|      AverageReturn |           -68.2 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|          StdReturn |            28.8 |\n",
      "|          MaxReturn |           -19.2 |\n",
      "|          MinReturn |            -135 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        7.19e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 14 ************\n",
      "----------------------------------------\n",
      "|               Time |             104 |\n",
      "|         Loss Delta |         0.00428 |\n",
      "|         Loss After |         -0.0943 |\n",
      "|          Iteration |              14 |\n",
      "|      AverageReturn |             -65 |\n",
      "|          StdReturn |            32.7 |\n",
      "|          MaxReturn |             4.2 |\n",
      "|          MinReturn |            -154 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |         7.7e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 15 ************\n",
      "----------------------------------------\n",
      "|               Time |             111 |\n",
      "|         Loss Delta |         -0.0138 |\n",
      "|         Loss After |         -0.0805 |\n",
      "|          Iteration |              15 |\n",
      "|      AverageReturn |           -72.2 |\n",
      "|          StdReturn |              31 |\n",
      "|          MaxReturn |            -4.8 |\n",
      "|          MinReturn |            -133 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        8.21e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 16 ************\n",
      "----------------------------------------\n",
      "|               Time |             119 |\n",
      "|         Loss Delta |        -0.00189 |\n",
      "|         Loss After |         -0.0786 |\n",
      "|          Iteration |              16 |\n",
      "|      AverageReturn |           -72.4 |\n",
      "|          StdReturn |            31.6 |\n",
      "|          MaxReturn |              27 |\n",
      "|          MinReturn |            -126 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        8.73e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 17 ************\n",
      "----------------------------------------\n",
      "|               Time |             126 |\n",
      "|         Loss Delta |          0.0752 |\n",
      "|         Loss After |          -0.154 |\n",
      "|          Iteration |              17 |\n",
      "|      AverageReturn |           -79.9 |\n",
      "|          StdReturn |            29.4 |\n",
      "|          MaxReturn |           -23.9 |\n",
      "|          MinReturn |            -146 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        9.24e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 18 ************\n",
      "----------------------------------------\n",
      "|               Time |             132 |\n",
      "|         Loss Delta |         -0.0812 |\n",
      "|         Loss After |         -0.0726 |\n",
      "|          Iteration |              18 |\n",
      "|      AverageReturn |           -71.3 |\n",
      "|          StdReturn |            29.1 |\n",
      "|          MaxReturn |           -6.24 |\n",
      "|          MinReturn |            -130 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        9.75e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 19 ************\n",
      "----------------------------------------\n",
      "|               Time |             139 |\n",
      "|         Loss Delta |          0.0206 |\n",
      "|         Loss After |         -0.0932 |\n",
      "|          Iteration |              19 |\n",
      "|      AverageReturn |           -66.1 |\n",
      "|          StdReturn |            28.2 |\n",
      "|          MaxReturn |           -6.45 |\n",
      "|          MinReturn |            -117 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.03e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 20 ************\n",
      "----------------------------------------\n",
      "|               Time |             144 |\n",
      "|         Loss Delta |         0.00906 |\n",
      "|         Loss After |          -0.102 |\n",
      "|          Iteration |              20 |\n",
      "|      AverageReturn |           -67.6 |\n",
      "|          StdReturn |              29 |\n",
      "|          MaxReturn |           -14.1 |\n",
      "|          MinReturn |            -143 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.08e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 21 ************\n",
      "----------------------------------------\n",
      "|               Time |             150 |\n",
      "|         Loss Delta |          0.0287 |\n",
      "|         Loss After |          -0.131 |\n",
      "|          Iteration |              21 |\n",
      "|      AverageReturn |           -55.6 |\n",
      "|          StdReturn |            30.3 |\n",
      "|          MaxReturn |            12.6 |\n",
      "|          MinReturn |            -127 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.13e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 22 ************\n",
      "----------------------------------------\n",
      "|               Time |             157 |\n",
      "|         Loss Delta |         -0.0451 |\n",
      "|         Loss After |         -0.0858 |\n",
      "|          Iteration |              22 |\n",
      "|      AverageReturn |           -68.1 |\n",
      "|          StdReturn |            25.9 |\n",
      "|          MaxReturn |           -23.7 |\n",
      "|          MinReturn |            -120 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.18e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 23 ************\n",
      "----------------------------------------\n",
      "|               Time |             164 |\n",
      "|         Loss Delta |         -0.0247 |\n",
      "|         Loss After |         -0.0611 |\n",
      "|          Iteration |              23 |\n",
      "|      AverageReturn |           -65.4 |\n",
      "|          StdReturn |            30.8 |\n",
      "|          MaxReturn |            47.8 |\n",
      "|          MinReturn |            -127 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.23e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 24 ************\n",
      "----------------------------------------\n",
      "|               Time |             171 |\n",
      "|         Loss Delta |          0.0206 |\n",
      "|         Loss After |         -0.0817 |\n",
      "|          Iteration |              24 |\n",
      "|      AverageReturn |           -56.3 |\n",
      "|          StdReturn |            27.9 |\n",
      "|          MaxReturn |           0.468 |\n",
      "|          MinReturn |            -118 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.28e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 25 ************\n",
      "----------------------------------------\n",
      "|               Time |             179 |\n",
      "|         Loss Delta |          0.0286 |\n",
      "|         Loss After |           -0.11 |\n",
      "|          Iteration |              25 |\n",
      "|      AverageReturn |           -56.4 |\n",
      "|          StdReturn |            27.6 |\n",
      "|          MaxReturn |           -8.03 |\n",
      "|          MinReturn |            -130 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.33e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 26 ************\n",
      "----------------------------------------\n",
      "|               Time |             186 |\n",
      "|         Loss Delta |         -0.0116 |\n",
      "|         Loss After |         -0.0988 |\n",
      "|          Iteration |              26 |\n",
      "|      AverageReturn |           -53.4 |\n",
      "|          StdReturn |            40.2 |\n",
      "|          MaxReturn |            12.4 |\n",
      "|          MinReturn |            -127 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.39e+05 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "********** Iteration 27 ************\n",
      "----------------------------------------\n",
      "|               Time |             194 |\n",
      "|         Loss Delta |        -0.00571 |\n",
      "|         Loss After |         -0.0931 |\n",
      "|          Iteration |              27 |\n",
      "|      AverageReturn |           -44.9 |\n",
      "|          StdReturn |            32.7 |\n",
      "|          MaxReturn |            1.82 |\n",
      "|          MinReturn |            -124 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.44e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 28 ************\n",
      "----------------------------------------\n",
      "|               Time |             201 |\n",
      "|         Loss Delta |         0.00241 |\n",
      "|         Loss After |         -0.0955 |\n",
      "|          Iteration |              28 |\n",
      "|      AverageReturn |           -47.3 |\n",
      "|          StdReturn |            31.7 |\n",
      "|          MaxReturn |            31.5 |\n",
      "|          MinReturn |            -132 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.49e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 29 ************\n",
      "----------------------------------------\n",
      "|               Time |             208 |\n",
      "|         Loss Delta |         -0.0107 |\n",
      "|         Loss After |         -0.0848 |\n",
      "|          Iteration |              29 |\n",
      "|      AverageReturn |           -41.2 |\n",
      "|          StdReturn |            30.1 |\n",
      "|          MaxReturn |            15.9 |\n",
      "|          MinReturn |           -98.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.54e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 30 ************\n",
      "----------------------------------------\n",
      "|               Time |             215 |\n",
      "|         Loss Delta |         -0.0393 |\n",
      "|         Loss After |         -0.0455 |\n",
      "|          Iteration |              30 |\n",
      "|      AverageReturn |           -40.5 |\n",
      "|          StdReturn |            32.7 |\n",
      "|          MaxReturn |            11.5 |\n",
      "|          MinReturn |            -138 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.59e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 31 ************\n",
      "----------------------------------------\n",
      "|               Time |             221 |\n",
      "|         Loss Delta |          0.0548 |\n",
      "|         Loss After |            -0.1 |\n",
      "|          Iteration |              31 |\n",
      "|      AverageReturn |           -40.1 |\n",
      "|          StdReturn |            26.3 |\n",
      "|          MaxReturn |            3.06 |\n",
      "|          MinReturn |            -102 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.64e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 32 ************\n",
      "----------------------------------------\n",
      "|               Time |             228 |\n",
      "|         Loss Delta |        -0.00429 |\n",
      "|         Loss After |         -0.0959 |\n",
      "|          Iteration |              32 |\n",
      "|      AverageReturn |           -35.2 |\n",
      "|          StdReturn |            25.4 |\n",
      "|          MaxReturn |            7.98 |\n",
      "|          MinReturn |           -77.2 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.69e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 33 ************\n",
      "----------------------------------------\n",
      "|               Time |             235 |\n",
      "|         Loss Delta |        0.000551 |\n",
      "|         Loss After |         -0.0965 |\n",
      "|          Iteration |              33 |\n",
      "|      AverageReturn |             -40 |\n",
      "|          StdReturn |            34.8 |\n",
      "|          MaxReturn |            28.2 |\n",
      "|          MinReturn |           -97.9 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.75e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 34 ************\n",
      "----------------------------------------\n",
      "|               Time |             243 |\n",
      "|         Loss Delta |        -0.00259 |\n",
      "|         Loss After |         -0.0939 |\n",
      "|          Iteration |              34 |\n",
      "|      AverageReturn |           -33.2 |\n",
      "|          StdReturn |            24.7 |\n",
      "|          MaxReturn |            8.41 |\n",
      "|          MinReturn |            -101 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |         1.8e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 35 ************\n",
      "----------------------------------------\n",
      "|               Time |             249 |\n",
      "|         Loss Delta |         0.00933 |\n",
      "|         Loss After |          -0.103 |\n",
      "|          Iteration |              35 |\n",
      "|      AverageReturn |           -38.7 |\n",
      "|          StdReturn |              27 |\n",
      "|          MaxReturn |            2.87 |\n",
      "|          MinReturn |           -91.5 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.85e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 36 ************\n",
      "----------------------------------------\n",
      "|               Time |             255 |\n",
      "|         Loss Delta |        -0.00523 |\n",
      "|         Loss After |          -0.098 |\n",
      "|          Iteration |              36 |\n",
      "|      AverageReturn |           -45.2 |\n",
      "|          StdReturn |              27 |\n",
      "|          MaxReturn |            1.24 |\n",
      "|          MinReturn |            -117 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |         1.9e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 37 ************\n",
      "----------------------------------------\n",
      "|               Time |             262 |\n",
      "|         Loss Delta |          0.0143 |\n",
      "|         Loss After |          -0.112 |\n",
      "|          Iteration |              37 |\n",
      "|      AverageReturn |           -33.7 |\n",
      "|          StdReturn |            30.9 |\n",
      "|          MaxReturn |            36.3 |\n",
      "|          MinReturn |            -107 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.95e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 38 ************\n",
      "----------------------------------------\n",
      "|               Time |             267 |\n",
      "|         Loss Delta |         -0.0145 |\n",
      "|         Loss After |         -0.0978 |\n",
      "|          Iteration |              38 |\n",
      "|      AverageReturn |           -24.8 |\n",
      "|          StdReturn |            23.5 |\n",
      "|          MaxReturn |            29.8 |\n",
      "|          MinReturn |           -68.6 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |           2e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 39 ************\n",
      "----------------------------------------\n",
      "|               Time |             274 |\n",
      "|         Loss Delta |          0.0121 |\n",
      "|         Loss After |           -0.11 |\n",
      "|          Iteration |              39 |\n",
      "|      AverageReturn |           -44.3 |\n",
      "|          StdReturn |              22 |\n",
      "|          MaxReturn |           -4.38 |\n",
      "|          MinReturn |           -84.3 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.05e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 40 ************\n",
      "----------------------------------------\n",
      "|               Time |             279 |\n",
      "|         Loss Delta |        -0.00658 |\n",
      "|         Loss After |          -0.103 |\n",
      "|          Iteration |              40 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      AverageReturn |             -38 |\n",
      "|          StdReturn |            17.6 |\n",
      "|          MaxReturn |           -6.27 |\n",
      "|          MinReturn |           -76.9 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |         2.1e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 41 ************\n",
      "----------------------------------------\n",
      "|               Time |             286 |\n",
      "|         Loss Delta |         -0.0456 |\n",
      "|         Loss After |         -0.0578 |\n",
      "|          Iteration |              41 |\n",
      "|      AverageReturn |           -26.5 |\n",
      "|          StdReturn |            25.5 |\n",
      "|          MaxReturn |            32.7 |\n",
      "|          MinReturn |           -99.8 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.16e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 42 ************\n",
      "----------------------------------------\n",
      "|               Time |             292 |\n",
      "|         Loss Delta |          0.0343 |\n",
      "|         Loss After |         -0.0921 |\n",
      "|          Iteration |              42 |\n",
      "|      AverageReturn |           -29.6 |\n",
      "|          StdReturn |            21.4 |\n",
      "|          MaxReturn |            12.5 |\n",
      "|          MinReturn |           -77.6 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.21e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 43 ************\n",
      "----------------------------------------\n",
      "|               Time |             297 |\n",
      "|         Loss Delta |         -0.0383 |\n",
      "|         Loss After |         -0.0538 |\n",
      "|          Iteration |              43 |\n",
      "|      AverageReturn |           -35.1 |\n",
      "|          StdReturn |            28.5 |\n",
      "|          MaxReturn |              18 |\n",
      "|          MinReturn |            -104 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.26e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 44 ************\n",
      "----------------------------------------\n",
      "|               Time |             304 |\n",
      "|         Loss Delta |          0.0779 |\n",
      "|         Loss After |          -0.132 |\n",
      "|          Iteration |              44 |\n",
      "|      AverageReturn |           -35.9 |\n",
      "|          StdReturn |            22.2 |\n",
      "|          MaxReturn |            13.4 |\n",
      "|          MinReturn |           -85.4 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.31e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 45 ************\n",
      "----------------------------------------\n",
      "|               Time |             310 |\n",
      "|         Loss Delta |           -0.08 |\n",
      "|         Loss After |         -0.0518 |\n",
      "|          Iteration |              45 |\n",
      "|      AverageReturn |           -25.1 |\n",
      "|          StdReturn |            17.7 |\n",
      "|          MaxReturn |            10.3 |\n",
      "|          MinReturn |           -58.4 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.36e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 46 ************\n",
      "----------------------------------------\n",
      "|               Time |             316 |\n",
      "|         Loss Delta |          0.0535 |\n",
      "|         Loss After |          -0.105 |\n",
      "|          Iteration |              46 |\n",
      "|      AverageReturn |           -31.2 |\n",
      "|          StdReturn |            23.4 |\n",
      "|          MaxReturn |            3.58 |\n",
      "|          MinReturn |            -100 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.41e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 47 ************\n",
      "----------------------------------------\n",
      "|               Time |             323 |\n",
      "|         Loss Delta |         -0.0063 |\n",
      "|         Loss After |         -0.0989 |\n",
      "|          Iteration |              47 |\n",
      "|      AverageReturn |           -28.5 |\n",
      "|          StdReturn |            23.6 |\n",
      "|          MaxReturn |            23.2 |\n",
      "|          MinReturn |           -82.3 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.46e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 48 ************\n",
      "----------------------------------------\n",
      "|               Time |             330 |\n",
      "|         Loss Delta |         -0.0341 |\n",
      "|         Loss After |         -0.0648 |\n",
      "|          Iteration |              48 |\n",
      "|      AverageReturn |           -29.7 |\n",
      "|          StdReturn |            25.8 |\n",
      "|          MaxReturn |            27.4 |\n",
      "|          MinReturn |           -90.9 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.52e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 49 ************\n",
      "----------------------------------------\n",
      "|               Time |             336 |\n",
      "|         Loss Delta |          0.0136 |\n",
      "|         Loss After |         -0.0784 |\n",
      "|          Iteration |              49 |\n",
      "|      AverageReturn |             -26 |\n",
      "|          StdReturn |            26.6 |\n",
      "|          MaxReturn |            24.5 |\n",
      "|          MinReturn |           -91.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.57e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 50 ************\n",
      "----------------------------------------\n",
      "|               Time |             344 |\n",
      "|         Loss Delta |          0.0292 |\n",
      "|         Loss After |          -0.108 |\n",
      "|          Iteration |              50 |\n",
      "|      AverageReturn |             -20 |\n",
      "|          StdReturn |            28.8 |\n",
      "|          MaxReturn |            43.6 |\n",
      "|          MinReturn |           -93.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.62e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 51 ************\n",
      "----------------------------------------\n",
      "|               Time |             351 |\n",
      "|         Loss Delta |         -0.0561 |\n",
      "|         Loss After |         -0.0515 |\n",
      "|          Iteration |              51 |\n",
      "|      AverageReturn |           -26.6 |\n",
      "|          StdReturn |            29.9 |\n",
      "|          MaxReturn |              27 |\n",
      "|          MinReturn |            -122 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.67e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 52 ************\n",
      "----------------------------------------\n",
      "|               Time |             358 |\n",
      "|         Loss Delta |          0.0326 |\n",
      "|         Loss After |          -0.084 |\n",
      "|          Iteration |              52 |\n",
      "|      AverageReturn |           -23.1 |\n",
      "|          StdReturn |            27.8 |\n",
      "|          MaxReturn |            39.3 |\n",
      "|          MinReturn |           -82.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.72e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 53 ************\n",
      "----------------------------------------\n",
      "|               Time |             364 |\n",
      "|         Loss Delta |         -0.0193 |\n",
      "|         Loss After |         -0.0648 |\n",
      "|          Iteration |              53 |\n",
      "|      AverageReturn |           -21.5 |\n",
      "|          StdReturn |              28 |\n",
      "|          MaxReturn |            14.5 |\n",
      "|          MinReturn |           -95.8 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     TimestepsSoFar |        2.77e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 54 ************\n",
      "----------------------------------------\n",
      "|               Time |             370 |\n",
      "|         Loss Delta |          0.0178 |\n",
      "|         Loss After |         -0.0826 |\n",
      "|          Iteration |              54 |\n",
      "|      AverageReturn |           -23.5 |\n",
      "|          StdReturn |            24.1 |\n",
      "|          MaxReturn |            10.1 |\n",
      "|          MinReturn |           -66.4 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.82e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 55 ************\n",
      "----------------------------------------\n",
      "|               Time |             375 |\n",
      "|         Loss Delta |          0.0352 |\n",
      "|         Loss After |          -0.118 |\n",
      "|          Iteration |              55 |\n",
      "|      AverageReturn |           -15.7 |\n",
      "|          StdReturn |            22.3 |\n",
      "|          MaxReturn |            30.6 |\n",
      "|          MinReturn |           -77.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.88e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 56 ************\n",
      "----------------------------------------\n",
      "|               Time |             382 |\n",
      "|         Loss Delta |         -0.0662 |\n",
      "|         Loss After |         -0.0517 |\n",
      "|          Iteration |              56 |\n",
      "|      AverageReturn |           -22.9 |\n",
      "|          StdReturn |            24.9 |\n",
      "|          MaxReturn |            25.1 |\n",
      "|          MinReturn |           -84.1 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.93e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 57 ************\n",
      "----------------------------------------\n",
      "|               Time |             389 |\n",
      "|         Loss Delta |           -0.01 |\n",
      "|         Loss After |         -0.0416 |\n",
      "|          Iteration |              57 |\n",
      "|      AverageReturn |           -20.7 |\n",
      "|          StdReturn |            23.8 |\n",
      "|          MaxReturn |            25.5 |\n",
      "|          MinReturn |           -87.1 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        2.98e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 58 ************\n",
      "----------------------------------------\n",
      "|               Time |             396 |\n",
      "|         Loss Delta |          0.0736 |\n",
      "|         Loss After |          -0.115 |\n",
      "|          Iteration |              58 |\n",
      "|      AverageReturn |           -14.2 |\n",
      "|          StdReturn |            18.9 |\n",
      "|          MaxReturn |            17.9 |\n",
      "|          MinReturn |           -59.3 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.03e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 59 ************\n",
      "----------------------------------------\n",
      "|               Time |             401 |\n",
      "|         Loss Delta |         -0.0211 |\n",
      "|         Loss After |         -0.0941 |\n",
      "|          Iteration |              59 |\n",
      "|      AverageReturn |           -11.7 |\n",
      "|          StdReturn |            17.6 |\n",
      "|          MaxReturn |            26.6 |\n",
      "|          MinReturn |           -51.6 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.08e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 60 ************\n",
      "----------------------------------------\n",
      "|               Time |             408 |\n",
      "|         Loss Delta |           0.038 |\n",
      "|         Loss After |          -0.132 |\n",
      "|          Iteration |              60 |\n",
      "|      AverageReturn |           -18.7 |\n",
      "|          StdReturn |              25 |\n",
      "|          MaxReturn |              18 |\n",
      "|          MinReturn |           -96.8 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.13e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 61 ************\n",
      "----------------------------------------\n",
      "|               Time |             415 |\n",
      "|         Loss Delta |         -0.0228 |\n",
      "|         Loss After |          -0.109 |\n",
      "|          Iteration |              61 |\n",
      "|      AverageReturn |           -18.1 |\n",
      "|          StdReturn |            21.3 |\n",
      "|          MaxReturn |            23.7 |\n",
      "|          MinReturn |           -69.9 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.18e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 62 ************\n",
      "----------------------------------------\n",
      "|               Time |             421 |\n",
      "|         Loss Delta |          -0.054 |\n",
      "|         Loss After |         -0.0553 |\n",
      "|          Iteration |              62 |\n",
      "|      AverageReturn |           -22.2 |\n",
      "|          StdReturn |            17.6 |\n",
      "|          MaxReturn |             6.9 |\n",
      "|          MinReturn |           -71.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.23e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 63 ************\n",
      "----------------------------------------\n",
      "|               Time |             429 |\n",
      "|         Loss Delta |          0.0544 |\n",
      "|         Loss After |           -0.11 |\n",
      "|          Iteration |              63 |\n",
      "|      AverageReturn |             -23 |\n",
      "|          StdReturn |            22.8 |\n",
      "|          MaxReturn |            13.3 |\n",
      "|          MinReturn |           -90.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.29e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 64 ************\n",
      "----------------------------------------\n",
      "|               Time |             436 |\n",
      "|         Loss Delta |        -0.00505 |\n",
      "|         Loss After |          -0.105 |\n",
      "|          Iteration |              64 |\n",
      "|      AverageReturn |           -21.9 |\n",
      "|          StdReturn |            25.4 |\n",
      "|          MaxReturn |            20.1 |\n",
      "|          MinReturn |           -70.6 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.34e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 65 ************\n",
      "----------------------------------------\n",
      "|               Time |             443 |\n",
      "|         Loss Delta |         0.00784 |\n",
      "|         Loss After |          -0.113 |\n",
      "|          Iteration |              65 |\n",
      "|      AverageReturn |           -21.3 |\n",
      "|          StdReturn |            21.6 |\n",
      "|          MaxReturn |            30.5 |\n",
      "|          MinReturn |           -72.2 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.39e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 66 ************\n",
      "----------------------------------------\n",
      "|               Time |             449 |\n",
      "|         Loss Delta |         -0.0278 |\n",
      "|         Loss After |         -0.0847 |\n",
      "|          Iteration |              66 |\n",
      "|      AverageReturn |           -16.1 |\n",
      "|          StdReturn |            32.9 |\n",
      "|          MaxReturn |            26.9 |\n",
      "|          MinReturn |            -151 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.44e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 67 ************\n",
      "----------------------------------------\n",
      "|               Time |             455 |\n",
      "|         Loss Delta |          0.0115 |\n",
      "|         Loss After |         -0.0962 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|          Iteration |              67 |\n",
      "|      AverageReturn |           -17.9 |\n",
      "|          StdReturn |            22.1 |\n",
      "|          MaxReturn |            31.1 |\n",
      "|          MinReturn |           -64.3 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.49e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 68 ************\n",
      "----------------------------------------\n",
      "|               Time |             461 |\n",
      "|         Loss Delta |        -0.00787 |\n",
      "|         Loss After |         -0.0883 |\n",
      "|          Iteration |              68 |\n",
      "|      AverageReturn |           -11.5 |\n",
      "|          StdReturn |              27 |\n",
      "|          MaxReturn |            32.9 |\n",
      "|          MinReturn |             -79 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.54e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 69 ************\n",
      "----------------------------------------\n",
      "|               Time |             467 |\n",
      "|         Loss Delta |         -0.0301 |\n",
      "|         Loss After |         -0.0582 |\n",
      "|          Iteration |              69 |\n",
      "|      AverageReturn |           0.606 |\n",
      "|          StdReturn |            18.2 |\n",
      "|          MaxReturn |            31.6 |\n",
      "|          MinReturn |           -46.8 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.59e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 70 ************\n",
      "----------------------------------------\n",
      "|               Time |             474 |\n",
      "|         Loss Delta |          0.0103 |\n",
      "|         Loss After |         -0.0684 |\n",
      "|          Iteration |              70 |\n",
      "|      AverageReturn |           -6.14 |\n",
      "|          StdReturn |            19.3 |\n",
      "|          MaxReturn |            34.2 |\n",
      "|          MinReturn |           -55.6 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.65e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 71 ************\n",
      "----------------------------------------\n",
      "|               Time |             482 |\n",
      "|         Loss Delta |        -0.00816 |\n",
      "|         Loss After |         -0.0603 |\n",
      "|          Iteration |              71 |\n",
      "|      AverageReturn |          -0.715 |\n",
      "|          StdReturn |            21.6 |\n",
      "|          MaxReturn |            79.3 |\n",
      "|          MinReturn |           -37.2 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |         3.7e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 72 ************\n",
      "----------------------------------------\n",
      "|               Time |             488 |\n",
      "|         Loss Delta |          0.0104 |\n",
      "|         Loss After |         -0.0706 |\n",
      "|          Iteration |              72 |\n",
      "|      AverageReturn |           -1.49 |\n",
      "|          StdReturn |            20.6 |\n",
      "|          MaxReturn |            40.8 |\n",
      "|          MinReturn |           -38.9 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.75e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 73 ************\n",
      "----------------------------------------\n",
      "|               Time |             495 |\n",
      "|         Loss Delta |          0.0349 |\n",
      "|         Loss After |          -0.106 |\n",
      "|          Iteration |              73 |\n",
      "|      AverageReturn |           -9.08 |\n",
      "|          StdReturn |              22 |\n",
      "|          MaxReturn |            31.5 |\n",
      "|          MinReturn |           -60.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |         3.8e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 74 ************\n",
      "----------------------------------------\n",
      "|               Time |             503 |\n",
      "|         Loss Delta |          0.0124 |\n",
      "|         Loss After |          -0.118 |\n",
      "|          Iteration |              74 |\n",
      "|      AverageReturn |           -5.99 |\n",
      "|          StdReturn |            21.9 |\n",
      "|          MaxReturn |            29.2 |\n",
      "|          MinReturn |           -65.9 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.85e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 75 ************\n",
      "----------------------------------------\n",
      "|               Time |             508 |\n",
      "|         Loss Delta |         -0.0785 |\n",
      "|         Loss After |         -0.0395 |\n",
      "|          Iteration |              75 |\n",
      "|      AverageReturn |           -2.59 |\n",
      "|          StdReturn |            23.2 |\n",
      "|          MaxReturn |            45.1 |\n",
      "|          MinReturn |           -62.1 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |         3.9e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 76 ************\n",
      "----------------------------------------\n",
      "|               Time |             514 |\n",
      "|         Loss Delta |          0.0513 |\n",
      "|         Loss After |         -0.0908 |\n",
      "|          Iteration |              76 |\n",
      "|      AverageReturn |            2.04 |\n",
      "|          StdReturn |            20.8 |\n",
      "|          MaxReturn |            36.1 |\n",
      "|          MinReturn |           -53.9 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        3.95e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 77 ************\n",
      "----------------------------------------\n",
      "|               Time |             522 |\n",
      "|         Loss Delta |         0.00846 |\n",
      "|         Loss After |         -0.0993 |\n",
      "|          Iteration |              77 |\n",
      "|      AverageReturn |           0.727 |\n",
      "|          StdReturn |            22.4 |\n",
      "|          MaxReturn |            36.5 |\n",
      "|          MinReturn |           -52.9 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |           4e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 78 ************\n",
      "----------------------------------------\n",
      "|               Time |             530 |\n",
      "|         Loss Delta |          -0.063 |\n",
      "|         Loss After |         -0.0362 |\n",
      "|          Iteration |              78 |\n",
      "|      AverageReturn |            1.77 |\n",
      "|          StdReturn |            35.4 |\n",
      "|          MaxReturn |            50.8 |\n",
      "|          MinReturn |            -167 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.06e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 79 ************\n",
      "----------------------------------------\n",
      "|               Time |             536 |\n",
      "|         Loss Delta |          0.0492 |\n",
      "|         Loss After |         -0.0855 |\n",
      "|          Iteration |              79 |\n",
      "|      AverageReturn |            6.47 |\n",
      "|          StdReturn |              25 |\n",
      "|          MaxReturn |            56.5 |\n",
      "|          MinReturn |           -44.9 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.11e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 80 ************\n",
      "----------------------------------------\n",
      "|               Time |             542 |\n",
      "|         Loss Delta |        -0.00885 |\n",
      "|         Loss After |         -0.0766 |\n",
      "|          Iteration |              80 |\n",
      "|      AverageReturn |            4.18 |\n",
      "|          StdReturn |            23.2 |\n",
      "|          MaxReturn |            38.5 |\n",
      "|          MinReturn |             -69 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.16e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 81 ************\n",
      "----------------------------------------\n",
      "|               Time |             548 |\n",
      "|         Loss Delta |          -0.021 |\n",
      "|         Loss After |         -0.0557 |\n",
      "|          Iteration |              81 |\n",
      "|      AverageReturn |            12.9 |\n",
      "|          StdReturn |              22 |\n",
      "|          MaxReturn |              56 |\n",
      "|          MinReturn |           -40.1 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.21e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 82 ************\n",
      "----------------------------------------\n",
      "|               Time |             556 |\n",
      "|         Loss Delta |         0.00796 |\n",
      "|         Loss After |         -0.0636 |\n",
      "|          Iteration |              82 |\n",
      "|      AverageReturn |            3.82 |\n",
      "|          StdReturn |            25.2 |\n",
      "|          MaxReturn |              67 |\n",
      "|          MinReturn |           -49.5 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.26e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 83 ************\n",
      "----------------------------------------\n",
      "|               Time |             561 |\n",
      "|         Loss Delta |          0.0102 |\n",
      "|         Loss After |         -0.0738 |\n",
      "|          Iteration |              83 |\n",
      "|      AverageReturn |            4.71 |\n",
      "|          StdReturn |            22.4 |\n",
      "|          MaxReturn |            45.4 |\n",
      "|          MinReturn |             -63 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.31e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 84 ************\n",
      "----------------------------------------\n",
      "|               Time |             568 |\n",
      "|         Loss Delta |         -0.0621 |\n",
      "|         Loss After |         -0.0117 |\n",
      "|          Iteration |              84 |\n",
      "|      AverageReturn |           0.988 |\n",
      "|          StdReturn |            24.5 |\n",
      "|          MaxReturn |              64 |\n",
      "|          MinReturn |           -44.1 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.36e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 85 ************\n",
      "----------------------------------------\n",
      "|               Time |             575 |\n",
      "|         Loss Delta |          0.0534 |\n",
      "|         Loss After |         -0.0652 |\n",
      "|          Iteration |              85 |\n",
      "|      AverageReturn |             1.6 |\n",
      "|          StdReturn |            21.1 |\n",
      "|          MaxReturn |            33.4 |\n",
      "|          MinReturn |           -51.1 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.42e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 86 ************\n",
      "----------------------------------------\n",
      "|               Time |             582 |\n",
      "|         Loss Delta |          0.0355 |\n",
      "|         Loss After |          -0.101 |\n",
      "|          Iteration |              86 |\n",
      "|      AverageReturn |            11.8 |\n",
      "|          StdReturn |            21.5 |\n",
      "|          MaxReturn |              73 |\n",
      "|          MinReturn |           -34.2 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.47e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 87 ************\n",
      "----------------------------------------\n",
      "|               Time |             588 |\n",
      "|         Loss Delta |         -0.0218 |\n",
      "|         Loss After |         -0.0789 |\n",
      "|          Iteration |              87 |\n",
      "|      AverageReturn |            13.7 |\n",
      "|          StdReturn |            16.8 |\n",
      "|          MaxReturn |            52.9 |\n",
      "|          MinReturn |           -28.5 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.52e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 88 ************\n",
      "----------------------------------------\n",
      "|               Time |             594 |\n",
      "|         Loss Delta |         -0.0262 |\n",
      "|         Loss After |         -0.0527 |\n",
      "|          Iteration |              88 |\n",
      "|      AverageReturn |              14 |\n",
      "|          StdReturn |            32.8 |\n",
      "|          MaxReturn |            56.9 |\n",
      "|          MinReturn |           -81.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.57e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 89 ************\n",
      "----------------------------------------\n",
      "|               Time |             601 |\n",
      "|         Loss Delta |          0.0281 |\n",
      "|         Loss After |         -0.0807 |\n",
      "|          Iteration |              89 |\n",
      "|      AverageReturn |            19.4 |\n",
      "|          StdReturn |            27.2 |\n",
      "|          MaxReturn |              73 |\n",
      "|          MinReturn |             -52 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.62e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 90 ************\n",
      "----------------------------------------\n",
      "|               Time |             607 |\n",
      "|         Loss Delta |         0.00564 |\n",
      "|         Loss After |         -0.0864 |\n",
      "|          Iteration |              90 |\n",
      "|      AverageReturn |            9.25 |\n",
      "|          StdReturn |            29.1 |\n",
      "|          MaxReturn |            64.3 |\n",
      "|          MinReturn |           -61.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.67e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 91 ************\n",
      "----------------------------------------\n",
      "|               Time |             614 |\n",
      "|         Loss Delta |         -0.0254 |\n",
      "|         Loss After |          -0.061 |\n",
      "|          Iteration |              91 |\n",
      "|      AverageReturn |            18.6 |\n",
      "|          StdReturn |            30.4 |\n",
      "|          MaxReturn |            88.1 |\n",
      "|          MinReturn |           -51.5 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.72e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 92 ************\n",
      "----------------------------------------\n",
      "|               Time |             621 |\n",
      "|         Loss Delta |          0.0233 |\n",
      "|         Loss After |         -0.0842 |\n",
      "|          Iteration |              92 |\n",
      "|      AverageReturn |            16.7 |\n",
      "|          StdReturn |            34.2 |\n",
      "|          MaxReturn |            87.4 |\n",
      "|          MinReturn |           -56.2 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.77e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 93 ************\n",
      "----------------------------------------\n",
      "|               Time |             627 |\n",
      "|         Loss Delta |        -0.00276 |\n",
      "|         Loss After |         -0.0814 |\n",
      "|          Iteration |              93 |\n",
      "|      AverageReturn |            5.06 |\n",
      "|          StdReturn |            29.3 |\n",
      "|          MaxReturn |            52.4 |\n",
      "|          MinReturn |           -72.3 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.83e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 94 ************\n",
      "----------------------------------------\n",
      "|               Time |             634 |\n",
      "|         Loss Delta |         -0.0292 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         Loss After |         -0.0523 |\n",
      "|          Iteration |              94 |\n",
      "|      AverageReturn |            12.5 |\n",
      "|          StdReturn |            23.9 |\n",
      "|          MaxReturn |            47.7 |\n",
      "|          MinReturn |           -52.6 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.88e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 95 ************\n",
      "----------------------------------------\n",
      "|               Time |             641 |\n",
      "|         Loss Delta |         -0.0138 |\n",
      "|         Loss After |         -0.0384 |\n",
      "|          Iteration |              95 |\n",
      "|      AverageReturn |           -4.66 |\n",
      "|          StdReturn |            36.3 |\n",
      "|          MaxReturn |            58.6 |\n",
      "|          MinReturn |           -83.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.93e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 96 ************\n",
      "----------------------------------------\n",
      "|               Time |             648 |\n",
      "|         Loss Delta |           0.016 |\n",
      "|         Loss After |         -0.0544 |\n",
      "|          Iteration |              96 |\n",
      "|      AverageReturn |            3.22 |\n",
      "|          StdReturn |            32.8 |\n",
      "|          MaxReturn |            73.2 |\n",
      "|          MinReturn |           -71.9 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        4.98e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 97 ************\n",
      "----------------------------------------\n",
      "|               Time |             655 |\n",
      "|         Loss Delta |           0.015 |\n",
      "|         Loss After |         -0.0694 |\n",
      "|          Iteration |              97 |\n",
      "|      AverageReturn |           -0.11 |\n",
      "|          StdReturn |              32 |\n",
      "|          MaxReturn |            46.3 |\n",
      "|          MinReturn |           -92.5 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        5.03e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 98 ************\n",
      "----------------------------------------\n",
      "|               Time |             662 |\n",
      "|         Loss Delta |        -0.00505 |\n",
      "|         Loss After |         -0.0644 |\n",
      "|          Iteration |              98 |\n",
      "|      AverageReturn |              16 |\n",
      "|          StdReturn |            24.4 |\n",
      "|          MaxReturn |            72.8 |\n",
      "|          MinReturn |           -43.7 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        5.08e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 99 ************\n",
      "----------------------------------------\n",
      "|               Time |             668 |\n",
      "|         Loss Delta |         0.00644 |\n",
      "|         Loss After |         -0.0708 |\n",
      "|          Iteration |              99 |\n",
      "|      AverageReturn |            17.6 |\n",
      "|          StdReturn |            32.4 |\n",
      "|          MaxReturn |            62.3 |\n",
      "|          MinReturn |            -110 |\n",
      "|          EpLenMean |             151 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        5.13e+05 |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "runmain('HalfCheetah-v1', \n",
    "        n_iter = 100, \n",
    "        batch_size = 5000 , \n",
    "        discount = 0.9,\n",
    "        learning_rate = 1e-2,\n",
    "        n_experiments = 1,  \n",
    "        dont_normalize_advantages = False,\n",
    "        reward_to_go = True,\n",
    "        nn_baseline = True,\n",
    "        exp_name = 'lb_bl_rtg_dna',\n",
    "        ep_len = 150,\n",
    "        n_layers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runmain('InvertedPendulum-v1', \n",
    "        n_iter = 100, \n",
    "        batch_size = 5000 , \n",
    "        n_experiments = 1,  \n",
    "        dont_normalize_advantages = False,\n",
    "        reward_to_go = True,\n",
    "        nn_baseline = True,\n",
    "        exp_name = 'sb_bl_rtg_dna',\n",
    "        n_layers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def main():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('env_name', type=str)\n",
    "    parser.add_argument('--exp_name', type=str, default='vpg')\n",
    "    parser.add_argument('--render', action='store_true')\n",
    "    parser.add_argument('--discount', type=float, default=1.0)\n",
    "    parser.add_argument('--n_iter', '-n', type=int, default=100)\n",
    "    parser.add_argument('--batch_size', '-b', type=int, default=1000)\n",
    "    parser.add_argument('--ep_len', '-ep', type=float, default=-1.)\n",
    "    parser.add_argument('--learning_rate', '-lr', type=float, default=5e-3)\n",
    "    parser.add_argument('--reward_to_go', '-rtg', action='store_true')\n",
    "    parser.add_argument('--dont_normalize_advantages', '-dna', action='store_true')\n",
    "    parser.add_argument('--nn_baseline', '-bl', action='store_true')\n",
    "    parser.add_argument('--seed', type=int, default=1)\n",
    "    parser.add_argument('--n_experiments', '-e', type=int, default=1)\n",
    "    parser.add_argument('--n_layers', '-l', type=int, default=1)\n",
    "    parser.add_argument('--size', '-s', type=int, default=32)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if not(os.path.exists('data')):\n",
    "        os.makedirs('data')\n",
    "    logdir = args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "    logdir = os.path.join('data', logdir)\n",
    "    if not(os.path.exists(logdir)):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    max_path_length = args.ep_len if args.ep_len > 0 else None\n",
    "\n",
    "    for e in range(args.n_experiments):\n",
    "        seed = args.seed + 10*e\n",
    "        print('Running experiment with seed %d'%seed)\n",
    "        def train_func():\n",
    "            train_PG(\n",
    "                exp_name=args.exp_name,\n",
    "                env_name=args.env_name,\n",
    "                n_iter=args.n_iter,\n",
    "                gamma=args.discount,\n",
    "                min_timesteps_per_batch=args.batch_size,\n",
    "                max_path_length=max_path_length,\n",
    "                learning_rate=args.learning_rate,\n",
    "                reward_to_go=args.reward_to_go,\n",
    "                animate=args.render,\n",
    "                logdir=os.path.join(logdir,'%d'%seed),\n",
    "                normalize_advantages=not(args.dont_normalize_advantages),\n",
    "                nn_baseline=args.nn_baseline, \n",
    "                seed=seed,\n",
    "                n_layers=args.n_layers,\n",
    "                size=args.size\n",
    "                )\n",
    "        # Awkward hacky process runs, because Tensorflow does not like\n",
    "        # repeatedly calling train_PG in the same thread.\n",
    "        p = Process(target=train_func, args=tuple())\n",
    "        p.start()\n",
    "        p.join()\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
